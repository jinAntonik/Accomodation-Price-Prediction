{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3Ja9sFWaFTy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import winsound\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.chrome.options import Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j75JpBKaFT3"
      },
      "outputs": [],
      "source": [
        "def melody()-> None:\n",
        "  '''Функция вызывает звуковые сигналы,\n",
        "  предупреждающие о капче\n",
        "  '''\n",
        "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
        "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
        "    winsound.PlaySound('SystemHand', winsound.SND_ALIAS)\n",
        "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)\n",
        "    winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PgLpCAqBaFT4"
      },
      "outputs": [],
      "source": [
        "def anticaptcha_hands(bad_url: str)-> None:\n",
        "  '''Функция открывает веб-страницу с капчей,\n",
        "  дает время на ее прохождение вручную\n",
        "  и передает кукис в вебдрайвер, чтобы\n",
        "  капча не возникла на следующей странице\n",
        "  '''\n",
        "    driver.get(bad_url)\n",
        "    time.sleep(10)\n",
        "    se.headers.update(headers)\n",
        "    for cookie in driver.get_cookies():\n",
        "        c = {cookie['name']: cookie['value']}\n",
        "        se.cookies.update(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем пустой датафрейм с необходимыми столбцами"
      ],
      "metadata": {
        "id": "yRdlW_r91HVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rrMZNl_aFT4"
      },
      "outputs": [],
      "source": [
        "link = \"link\"\n",
        "title = \"title\"\n",
        "addr = \"addr\"\n",
        "price = \"price\"\n",
        "subway = \"subway\"\n",
        "subway_dist = \"subway_dist\"\n",
        "highway = \"highway\"\n",
        "highway_dist = \"highway_dist\"\n",
        "flat_info = \"flat_info\"\n",
        "obshchaya_info = \"obshchaya_info\"\n",
        "house_info = \"house_info\"\n",
        "opisanie = \"opisanie\"\n",
        "\n",
        "with open(f\"data10.csv\", \"w\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file, delimiter = '$', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    writer.writerow(\n",
        "    (\n",
        "    link,\n",
        "    title,\n",
        "    addr,\n",
        "    price,\n",
        "    subway,\n",
        "    subway_dist,\n",
        "    highway,\n",
        "    highway_dist,\n",
        "    flat_info,\n",
        "    obshchaya_info,\n",
        "    house_info,\n",
        "    opisanie\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формируем список из объявлений, проходясь по всем страницам для каждого района Петербурга"
      ],
      "metadata": {
        "id": "CpnqU-LA7HoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "href = []\n",
        "ob = 0 # счетчик объявлений\n",
        "\n",
        "option = webdriver.ChromeOptions()\n",
        "option.add_argument(\"--disable-notifications\")\n",
        "driver = webdriver.Chrome(os.getcwd()+\"\\chromedriver.exe\", options=option) # держим driver открытым\n",
        "time.sleep(5)\n",
        "\n",
        "headers = {\n",
        "        \"Accept\": \"*/*\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.174 YaBrowser/22.1.5.810 Yowser/2.5 Safari/537.36\"\n",
        "    }\n",
        "se = requests.session()\n",
        "\n",
        "\n",
        "for distr in range(133, 150+1): # по каждому району, начало 133\n",
        "    \n",
        "    url = \"https://spb.cian.ru/cat.php?deal_type=sale&district[0]=\"+str(distr)+\"&engine_version=2&object_type[0]=1&offer_type=flat&p=\"\n",
        "    if requests.get(url, headers=headers, cookies = se.cookies).text.find('Captcha')!=-1:\n",
        "        anticaptcha_hands(url)\n",
        "\n",
        "    it = 0   \n",
        "    for item in range(1, 54+1): # по каждой странице\n",
        "        it += 1 # счетчик страниц\n",
        "        full_url = url+f\"{item}\"+\"&region=2&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room9=1\"\n",
        "        if requests.get(full_url, headers=headers, cookies = se.cookies).text.find('Captcha')!=-1:\n",
        "            print(\"Captcha \" * 10)\n",
        "            time.sleep(15)\n",
        "            anticaptcha_hands(full_url)\n",
        "\n",
        "        req = requests.get(full_url, headers=headers, cookies = se.cookies) # защита от второй капчи подряд\n",
        "        src = req.text\n",
        "        if src.find('Captcha')!=-1:\n",
        "            print(\"Captcha \" * 10)\n",
        "            time.sleep(15)\n",
        "            anticaptcha_hands(full_url)\n",
        "            req = requests.get(full_url, headers=headers, cookies = se.cookies)\n",
        "            src = req.text\n",
        "\n",
        "        soup = BeautifulSoup(src, \"lxml\")\n",
        "        href_raw = soup.find_all(class_=\"_93444fe79c--link--eoxce\")\n",
        "\n",
        "        for item in href_raw: # для каждого объявления\n",
        "            item_text = item.get(\"href\")\n",
        "            href.append(item_text)\n",
        "            ob += 1\n",
        "\n",
        "            print(\"Район №\"+str(distr-132)+\", Стр. №\"+str(it)+\", Объявление №\"+str(ob))\n",
        "driver.close()"
      ],
      "metadata": {
        "id": "gfE11feL7bs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собираем информацию по каждому объявлению (=каждой ссылке) и помещаем в отдельный список"
      ],
      "metadata": {
        "id": "JFpyRH660a_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5enFjFesaFUk"
      },
      "outputs": [],
      "source": [
        "s = 0 # счетчик объявлений\n",
        "link = []\n",
        "title = []\n",
        "subway = []\n",
        "subway_dist = []\n",
        "highway = []\n",
        "highway_dist = []\n",
        "price = []\n",
        "addr = []\n",
        "flat_info = []\n",
        "obshchaya_info = []\n",
        "house_info = []\n",
        "opisanie = []\n",
        "\n",
        "option = webdriver.ChromeOptions()\n",
        "option.add_argument(\"--disable-notifications\")\n",
        "driver = webdriver.Chrome(os.getcwd()+\"\\chromedriver.exe\", options=option) # держим driver открытым\n",
        "headers = {\n",
        "        \"Accept\": \"*/*\",\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.119 YaBrowser/22.3.0.2430 Yowser/2.5 Safari/537.36\"\n",
        "}\n",
        "se = requests.session()\n",
        "\n",
        "\n",
        "for i in range(0, len(href)):\n",
        "    url = href[i]\n",
        "\n",
        "    if requests.get(url, headers=headers, cookies=se.cookies).text.find('Captcha')!=-1:\n",
        "        print(\"Captcha \" * 10)\n",
        "        melody()\n",
        "        time.sleep(15)\n",
        "        anticaptcha_hands(url)\n",
        "    req = requests.get(url, headers=headers, cookies=se.cookies)\n",
        "    src = req.text\n",
        "\n",
        "    if src.find('Captcha')!=-1:\n",
        "        print(\"Captcha \" * 10)\n",
        "        melody()\n",
        "        time.sleep(15)\n",
        "        anticaptcha_hands(url)\n",
        "        req = requests.get(url, headers=headers, cookies=se.cookies)\n",
        "        src = req.text\n",
        "    soup = BeautifulSoup(src, \"lxml\")\n",
        "\n",
        "\n",
        "    link.append(href[i])\n",
        "    \n",
        "\n",
        "    try:\n",
        "        title_raw = soup.find_all(class_=\"a10a3f92e9--title--UEAG3\")\n",
        "        title_raw0 = title_raw[0]\n",
        "    except IndexError:\n",
        "        title.append(\"\")\n",
        "    else:\n",
        "        if len(title_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(title_raw)):\n",
        "                ww = title_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            title.append(string)\n",
        "        else:\n",
        "            title.append(title_raw[0].text.strip())\n",
        "    \n",
        "    try:\n",
        "        addr_raw = soup.find_all(class_=\"a10a3f92e9--address--F06X3\")\n",
        "        addr_raw0 = addr_raw[0]\n",
        "    except IndexError:\n",
        "        addr.append(\"\")\n",
        "    else:\n",
        "        if len(addr_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(addr_raw)):\n",
        "                ww = addr_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            addr.append(string)\n",
        "        else:\n",
        "            addr.append(addr_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        flat_info_raw = soup.find_all(class_=\"a10a3f92e9--info-block--kXrDj\")\n",
        "        flat_info_raw0 = flat_info_raw[0]\n",
        "    except IndexError:\n",
        "        flat_info.append(\"\")\n",
        "    else:\n",
        "        if len(flat_info_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(flat_info_raw)):\n",
        "                ww = flat_info_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            flat_info.append(string)\n",
        "        else:\n",
        "            flat_info.append(flat_info_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        obshchaya_info_raw = soup.find_all(class_=\"a10a3f92e9--container--pZhdL\")\n",
        "        obshchaya_info_raw0 = obshchaya_info_raw[0]\n",
        "    except IndexError:\n",
        "        obshchaya_info.append(\"\")\n",
        "    else:\n",
        "        if len(obshchaya_info_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(obshchaya_info_raw)):\n",
        "                ww = obshchaya_info_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            obshchaya_info.append(string)\n",
        "        else:\n",
        "            obshchaya_info.append(obshchaya_info_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        house_info_raw = soup.find_all(class_=\"a10a3f92e9--content--ibqBi\")\n",
        "        house_info_raw0 = house_info_raw[0]\n",
        "    except IndexError:\n",
        "        house_info.append(\"\")\n",
        "    else:\n",
        "        if len(house_info_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(house_info_raw)):\n",
        "                ww = house_info_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            house_info.append(string)\n",
        "        else:\n",
        "            house_info.append(house_info_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        subway_raw = soup.find_all(class_=\"a10a3f92e9--underground_link--Sxo7K\")\n",
        "        subway_raw0 = subway_raw[0]\n",
        "    except:\n",
        "        subway.append(\"\")\n",
        "    else:\n",
        "        if len(subway_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(subway_raw)):\n",
        "                ww = subway_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            subway.append(string)\n",
        "        else:\n",
        "            subway.append(subway_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        subway_dist_raw = soup.find_all(class_=\"a10a3f92e9--underground_time--iOoHy\")\n",
        "        subway_dist_raw0 = subway_dist_raw[0]\n",
        "    except IndexError:\n",
        "        subway_dist.append(\"\")\n",
        "    else:\n",
        "        if len(subway_dist_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(subway_dist_raw)):\n",
        "                ww = subway_dist_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            subway_dist.append(string)\n",
        "        else:\n",
        "            subway_dist.append(subway_dist_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        highway_raw = soup.find_all(class_=\"a10a3f92e9--link--ulbh5 a10a3f92e9--highway_link--NOXPJ\")\n",
        "        highway_raw0 = highway_raw[0]\n",
        "    except:\n",
        "        highway.append(\"\")\n",
        "    else:\n",
        "        if len(highway_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(highway_raw)):\n",
        "                ww = highway_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            highway.append(string)\n",
        "        else:\n",
        "            highway.append(highway_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        highway_dist_raw = soup.find_all(class_=\"a10a3f92e9--highway_distance--wUNBn\")\n",
        "        highway_dist_raw0 = highway_dist_raw[0]\n",
        "    except IndexError:\n",
        "        highway_dist.append(\"\")\n",
        "    else:\n",
        "        if len(highway_dist_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(highway_dist_raw)):\n",
        "                ww = highway_dist_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            highway_dist.append(string)\n",
        "        else:\n",
        "            highway_dist.append(highway_dist_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        price_raw = soup.find_all(class_=\"a10a3f92e9--price_value--lqIK0\")\n",
        "        price_raw0 = price_raw[0]\n",
        "    except IndexError:\n",
        "        price.append(\"\")\n",
        "    else:\n",
        "        if len(price_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(price_raw)):\n",
        "                ww = price_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li])\n",
        "            price.append(string)\n",
        "        else:\n",
        "            price.append(price_raw[0].text.strip())\n",
        "\n",
        "\n",
        "    try:\n",
        "        opisanie_raw = soup.find_all(class_=\"a10a3f92e9--description-text--YNzWU\")\n",
        "        opisanie_raw0 = opisanie_raw[0]\n",
        "    except IndexError:\n",
        "        opisanie.append(\"\")\n",
        "    else:\n",
        "        if len(opisanie_raw) > 1:\n",
        "            li=[]\n",
        "            for n in range(0, len(opisanie_raw)):\n",
        "                ww = opisanie_raw[n].text.strip()\n",
        "                li.append(ww)\n",
        "            string = ';'.join([str(item) for item in li]).replace(\"\\n\", \"\")\n",
        "            opisanie.append(string)\n",
        "        else:\n",
        "            opisanie.append(opisanie_raw[0].text.strip().replace(\"\\n\", \"\"))\n",
        "\n",
        "    s +=1\n",
        "    print(\"Объявление №\"+str(s)+\", т.е.\"+str(s-1)+\", осталось \"+str(len(href)-s))\n",
        "\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заполняем датафрейм элементами из списков"
      ],
      "metadata": {
        "id": "OTRG5LFx0x3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFmFRETPaFUl"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(addr)):\n",
        "    with open(f\"data10.csv\", \"a\", encoding=\"utf-8\") as file:\n",
        "        writer = csv.writer(file, delimiter = '$', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "        writer.writerow(\n",
        "        (\n",
        "        link[i],\n",
        "        title[i],\n",
        "        addr[i],\n",
        "        price[i],\n",
        "        subway[i],\n",
        "        subway_dist[i],\n",
        "        highway[i],\n",
        "        highway_dist[i],\n",
        "        flat_info[i],\n",
        "        obshchaya_info[i],\n",
        "        house_info[i],\n",
        "        opisanie[i]\n",
        "        )\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CIAN_parser.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}